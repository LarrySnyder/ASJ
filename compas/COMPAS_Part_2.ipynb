{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LarrySnyder/ASJ/blob/main/compas/COMPAS_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMPASâ€”Part 2\n",
        "\n",
        "This file is read-only. To work with it, you first need to **save a copy to your Google Drive:**\n",
        "\n",
        "1. Go to the *File* menu. (The *File* menu inside the notebook, right below the filenameâ€”not the *File* menu in your browser, at the top of your screen.)\n",
        "2. Choose *Save a copy in Drive*. (Log in to your Google account, if necessary.) Feel free to move it to a different folder in your Drive, if you want.\n",
        "3. Colab should open up a new browser tab with your copy of the notebook. Double-click the filename at the top of the window and rename it `COMPAS [your name(s)]`. \n",
        "4. Close the original read-only notebook in your browser.\n"
      ],
      "metadata": {
        "id": "pdAvxkGROQfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "> ðŸ‘“ **Note:** This notebook is part of the *Algorithms and Social Justice* course at Lehigh University, Profs. Larry Snyder and Suzanne Edwards.\n",
        "---\n"
      ],
      "metadata": {
        "id": "n92vqZCZOWyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
        "from sklearn import tree, preprocessing"
      ],
      "metadata": {
        "id": "0kfJYCUkTMo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Previously On ...\n",
        "\n",
        "In the first COMPAS notebook, you loaded and filtered the data..."
      ],
      "metadata": {
        "id": "leO1SRVWS5hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv',\n",
        "                   usecols=[\"age\", \"c_charge_degree\", \"race\", \"age_cat\", \"score_text\", \"sex\", \"priors_count\", \n",
        "                    \"days_b_screening_arrest\", \"decile_score\", \"is_recid\", \"two_year_recid\", \"c_jail_in\", \"c_jail_out\"])\n",
        "pp_data = data.query('days_b_screening_arrest <= 30 & days_b_screening_arrest >= -30')\n",
        "pp_data = pp_data.query('race == \"Caucasian\" | race == \"African-American\"')"
      ],
      "metadata": {
        "id": "w0gLL244TISH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...built a histogram to visualize COMPAS scores for Black and white defendants..."
      ],
      "metadata": {
        "id": "UtvPxwp9TbMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(pp_data[pp_data[\"race\"] == \"African-American\"], x=\"decile_score\", discrete=True, color='orange', alpha=0.5)\n",
        "sns.histplot(pp_data[pp_data[\"race\"] == \"Caucasian\"], x=\"decile_score\", discrete=True, alpha=0.5)\n",
        "plt.legend(labels=[\"Black\", \"white\"]);"
      ],
      "metadata": {
        "id": "3bISlHOFTawh",
        "outputId": "5a2dc2e1-fbe8-424e-88c7-54c620e4607e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEHCAYAAABBW1qbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZuklEQVR4nO3de5RV5Z3m8e/DzcJLVJCwCAUUM2GMioJYSQADMRATpO3G7ijRZhCVDtoao6Gnu7X9Q7NWkqUrLo1MZjSoETAkxiba0GlvBIiSRB0LBW/gyBiQIgglKl5pAX/zx3lrU2JBFUXts6k6z2ets87e7779jpd6zn73Pu9WRGBmZgbQpegCzMzs4OFQMDOzjEPBzMwyDgUzM8s4FMzMLNOt6AIOxDHHHBM1NTVFl2Fm1qGsWLHi9Yjo09yyDh0KNTU11NXVFV2GmVmHImn93pa5+8jMzDIOBTMzyzgUzMws06GvKZiZtcaOHTuor69n+/btRZdSVlVVVVRXV9O9e/dWb+NQMLNOr76+niOOOIKamhokFV1OWUQEW7dupb6+nsGDB7d6O3cfmVmnt337dnr37l0xgQAgid69e+/32ZFDwcwqQiUFQqO2fOZcQ0HSUZIWSFojabWkUZJ6SVos6eX0fnRaV5JmSVor6VlJI/KszczMPinvM4VbgIci4nPAMGA1cBWwJCKGAEvSPMAZwJD0mgHcmnNtZlahagZVI6ndXjWDqvd5vK5duzJ8+HCGDRvGiBEj+OMf/wjAunXrGDp0aJs+w2mnnZbLj3dzu9As6UhgLHABQER8CHwoaRJwWlptLvA74J+BScC8KD3154l0ltEvIjblUd+AgYOo3/BqHrtuUfWAgWx4da8/KDSznK1/dSOx6tp225+GfW+fy3v27MnKlSsBePjhh7n66qt59NFH2+347SnPu48GAw3AXZKGASuAK4C+Tf7Qvwb0TdP9gQ1Ntq9PbbmEQv2GV7npkZfy2HWLZn7t2EKOa2bFe/vttzn66KM/0b5u3TqmTp3Ke++9B8BPfvITRo8eDcANN9zAz3/+c7p06cIZZ5zB9ddfn2330UcfcdFFF1FdXc33v//9A64vz1DoBowALo+IJyXdwu6uIgAiIiTt1/NAJc2g1L3EwIED26tWM7PcfPDBBwwfPpzt27ezadMmli5d+ol1Pv3pT7N48WKqqqp4+eWXOe+886irq+PBBx9k4cKFPPnkkxx66KG88cYb2TY7d+5kypQpDB06lGuuuaZdas3zmkI9UB8RT6b5BZRCYrOkfgDpfUtavhEY0GT76tT2MRExOyJqI6K2T59mB/kzMzuoNHYfrVmzhoceeojzzz+fUk/5bjt27OBb3/oWJ554Iueccw4vvvgiAL/97W+58MILOfTQQwHo1atXts3FF1/croEAOYZCRLwGbJDU2FcyHngRWARMS23TgIVpehFwfroLaSSwLa/rCWZmRRk1ahSvv/46DQ0NH2u/+eab6du3L6tWraKuro4PP/ywxX2NHj2aZcuWtesvtfO+++hyYL6kZ4HhwA+B64HTJb0MfDXNAzwAvAKsBW4HLs25NjOzsluzZg27du2id+/eH2vftm0b/fr1o0uXLtx9993s2rULgNNPP5277rqL999/H+Bj3UfTp09n4sSJTJ48mZ07d7ZLfbkOcxERK4HaZhaNb2bdAC7Lsx4zM4BBA/u3eMfQ/u5vXxqvKUBp+Im5c+fStWvXj61z6aWX8o1vfIN58+YxYcIEDjvsMAAmTJjAypUrqa2tpUePHkycOJEf/vCH2XYzZ85k27ZtTJ06lfnz59Oly4F919ee/VodSW1tbbT1Pl1Jhd591JH/uZt1NKtXr+a4444ruoxCNPfZJa2IiOa+sHuYCzMz282hYGZmGYeCmZllHApmZpZxKJiZWcahYGZmGYeCmVWcAQMHtevQ2QMGDjqgeg4//PBm22+77TbmzZsHwJw5c/jzn/98QMdpDT+j2cwqTnuPkpzXyMeXXHJJNj1nzhyGDh3KZz7zmVyO1chnCmZmOfvRj37ErFmzAPjud7/LuHHjAFi6dClTpkwB4JprrmHYsGGMHDmSzZs3A3Dddddx4403smDBAurq6pgyZQrDhw/ngw8+YMWKFXz5y1/mlFNO4etf/zqbNrXPUHEOBTOznI0ZM4bly5cDUFdXx7vvvsuOHTtYvnw5Y8eO5b333mPkyJGsWrWKsWPHcvvtt39s+7PPPpva2lrmz5/PypUr6datG5dffjkLFixgxYoVXHTRRe02Uqq7j8zMcnbKKaewYsUK3n77bQ455BBGjBhBXV0dy5cvZ9asWfTo0YMzzzwzW3fx4sX73N9LL73E888/z+mnnw7Arl276NevX7vU6lAwM8tZ9+7dGTx4MHPmzGH06NGcdNJJLFu2jLVr13LcccfRvXt3JAGl5zm3NOJpRHDCCSfw+OOPt3ut7j4yMyuDMWPGcOONNzJ27FjGjBnDbbfdxsknn5yFQUuOOOII3nnnHQCOPfZYGhoaslDYsWMHL7zwQrvU6TMFM6s41QMGtusdQ9UDWn408JgxY/jBD37AqFGjOOyww6iqqmLMmDGtPsYFF1zAJZdcQs+ePXn88cdZsGAB3/nOd9i2bRs7d+7kyiuv5IQTTjiQjwF46Ox2rqh1PHS2WXl56GwPnW1mZm3gUDAzs4xDwcwqQiV22bblMzsUzKzTq6qqYuvWrRUVDBHB1q1bqaqq2q/tfPeRmXV61dXV1NfX09DQUHQpZVVVVUV1dfV+beNQMLNOr/HHY9Yydx+ZmVnGoWBmZhmHgpmZZXINBUnrJD0naaWkutTWS9JiSS+n96NTuyTNkrRW0rOSRuRZm5mZfVI5zhS+EhHDm/yk+ipgSUQMAZakeYAzgCHpNQO4tQy1mZlZE0V0H00C5qbpucBZTdrnRckTwFGS2meAcDMza5W8QyGARyStkDQjtfWNiMbnxr0G9E3T/YENTbatT21mZlYmef9O4UsRsVHSp4HFktY0XRgRIWm/fmKYwmUGwMCBLQ9Xa2ZmrZfrmUJEbEzvW4D7gS8Amxu7hdL7lrT6RmBAk82rU9ue+5wdEbURUdunT588yzczqzi5hYKkwyQd0TgNfA14HlgETEurTQMWpulFwPnpLqSRwLYm3UxmZlYGeXYf9QXuT4+a6wb8IiIekvQUcK+k6cB6YHJa/wFgIrAWeB+4MMfazMysGbmFQkS8Agxrpn0rML6Z9gAuy6seMzNrmX/RbGZmGYeCmZllHApmZpZxKJiZWcahYGZmGYeCmZllHApmZpZxKJiZWcahYGZmGYeCmZllHApmZpZxKJiZWcahYGZmGYeCmZllHApmZpZxKJiZWcahYGZmGYeCmZllHApmZpZxKJiZWcahYGZmGYeCmZllHApmZpZxKJiZWcahYGZmGYeCmZllcg8FSV0lPSPpN2l+sKQnJa2V9CtJPVL7IWl+bVpek3dtZmb2ceU4U7gCWN1k/gbg5oj4LPAmMD21TwfeTO03p/XMzKyMcg0FSdXAXwB3pHkB44AFaZW5wFlpelKaJy0fn9Y3M7MyyftM4cfAPwEfpfnewFsRsTPN1wP903R/YANAWr4trf8xkmZIqpNU19DQkGftZmYVJ7dQkHQmsCUiVrTnfiNidkTURkRtnz592nPXZmYVr1uO+z4V+CtJE4Eq4FPALcBRkrqls4FqYGNafyMwAKiX1A04EtiaY31mZraH3M4UIuLqiKiOiBrgXGBpREwBlgFnp9WmAQvT9KI0T1q+NCIir/rMzOyTividwj8DMyWtpXTN4M7UfifQO7XPBK4qoDYzs4qWZ/dRJiJ+B/wuTb8CfKGZdbYD55SjHjMza55/0WxmZhmHgpmZZRwKZmaWcSiYmVnGoWBmZhmHgpmZZcpyS+rB6nvf+17RJZiZHVQqOhSuveTLhRx35h9+Uchxzcxa4u4jMzPLOBTMzCzTqlCQdGpr2szMrGNr7ZnC/2xlm5mZdWD7vNAsaRQwGugjaWaTRZ8CuuZZWGdXxJNGBw3sz7r19WU/rpl1HC3dfdQDODytd0ST9rfZ/UwEa4NYdW3Zj6lhvgW3EtQMqmb9qxtbXrGd+UtH57DPUIiIR4FHJc2JiPVlqsnMDsD6Vzf6S4e1WWt/p3CIpNlATdNtImJcHkWZmVkxWhsK/wrcBtwB7MqvHOus3KVh1jG0NhR2RsStuVZinZq7NMw6htbekvrvki6V1E9Sr8ZXrpWZmVnZtfZMYVp6/8cmbQH8l/Ytx8zMitSqUIiIwXkXYpaHrl38mxCz/dGqUJB0fnPtETGvfcupEOpSTF+3Km+oq10f+TchZvujtd1Hn28yXQWMB54GHAptER9x090/LfthZ069uOzHrFRFnaFUKt/d1n5a2310edN5SUcB9+RSkVknUNQZClTmWYrvbms/be1PeA/wdQYzs06mtdcU/p3S3UZQGgjvOODeFrapAh4DDknHWRAR10oaTOksozewApgaER9KOoRSd9QpwFbgmxGxbr8/kZmZtVlrrync2GR6J7A+IlrqSPtPYFxEvCupO/B7SQ8CM4GbI+IeSbcB04Fb0/ubEfFZSecCNwDf3J8PY2ZmB6ZV3UdpYLw1lEZKPRr4sBXbRES8m2a7p1cA44AFqX0ucFaanpTmScvHy1fqzMzKqrVPXpsM/B/gHGAy8KSkFofOltRV0kpgC7AY+H/AWxGxM61SD/RP0/2BDQBp+TZKXUx77nOGpDpJdQ0NDa0p38zKoPGOqyJe1n5a2310DfD5iNgCIKkP8Ft2f+NvVkTsAoanu5XuBz53ALU27nM2MBugtrY2Wljd9uD/gSwvvuOqc2htKHRpDIRkK/tx51JEvCVpGTAKOEpSt3Q2UA003ly8ERgA1EvqBhyZjmPtyP/Tmtm+tPYP+0OSHpZ0gaQLgP8AHtjXBpL6pDMEJPUETgdWA8vY/dS2acDCNL2I3WMsnQ0sjQifCZiZlVFLz2j+LNA3Iv5R0t8AX0qLHgfmt7DvfsBcSV0phc+9EfEbSS8C90j6PvAMcGda/07gbklrgTeAc9v0iczMrM1a6j76MXA1QETcB9wHIOnEtOwv97ZhRDwLnNxM+yvAF5pp307pQraZmRWkpe6jvhHx3J6Nqa0ml4rMzKwwLYXCUftY1rM9CzEzs+K1FAp1kr61Z6Okv6M0RIWZmXUiLV1TuBK4X9IUdodALdAD+Os8CzMzs/LbZyhExGZgtKSvAENT839ExNLcKzMzs7Jr7fMUllH6fYGZmXVilfd8RjMz2yuHgpmZZRwKZmaWcSiYmVnGoWBmZhmHgpmZZRwKZmaWcSiYmVmmtU9eMzsw6lLM09fk7z1m+8OhUEmK+sOc3HT3T8t+zJlTLy77Mc06ModCJYmPCvnDDP7jbNZR+NzazMwyDgUzM8s4FMzM2qhrF5BUyKtmUHUun8nXFMzM2mjXRxCrri3k2HndNOIzBTMzyzgUzMws41AwM7OMQ8HMzDK5hYKkAZKWSXpR0guSrkjtvSQtlvRyej86tUvSLElrJT0raURetZmZWfPyPFPYCfxDRBwPjAQuk3Q8cBWwJCKGAEvSPMAZwJD0mgHcmmNtZmbWjNxCISI2RcTTafodYDXQH5gEzE2rzQXOStOTgHlR8gRwlKR+edVnZmafVJbfKUiqAU4GngT6RsSmtOg1oG+a7g9saLJZfWrb1KQNSTMonUkwcODA3Gq2TsKjs5rtl9xDQdLhwK+BKyPibUnZsogISbE/+4uI2cBsgNra2v3a1ipQQYMAegBA66hy/TojqTulQJgfEfel5s2N3ULpfUtq3wgMaLJ5dWozM7MyyfPuIwF3Aqsj4qYmixYB09L0NGBhk/bz011II4FtTbqZzMysDPLsPjoVmAo8J2llavsX4HrgXknTgfXA5LTsAWAisBZ4H7gwx9rMzKwZuYVCRPwe0F4Wj29m/QAuy6seMzNrmW+RMDOzjEPBzMwyDgUzM8s4FMzMLONQMDOzjEPBzMwyDgUzM8s4FMzMLFOWUVLNKk5Ro7OmY5u1lUPBLA8Fjc4KHqHVDoy/UpiZWcahYGZmGYeCmZllHApmZpZxKJiZWcahYGZmGYeCmZllHApmZpZxKJiZWcahYGZmGYeCmZllHApmZpZxKJiZWcahYGZmGQ+dbdbZFPUsBz/HoVPILRQk/Qw4E9gSEUNTWy/gV0ANsA6YHBFvShJwCzAReB+4ICKezqs2s06toGc5+DkOnUOe0T4HmLBH21XAkogYAixJ8wBnAEPSawZwa451mZnZXuQWChHxGPDGHs2TgLlpei5wVpP2eVHyBHCUpH551WZmZs0rdydg34jYlKZfA/qm6f7Ahibr1ac2MzMro8KuDEVEALG/20maIalOUl1DQ0MOlZmZVa5y3320WVK/iNiUuoe2pPaNwIAm61Wntk+IiNnAbIDa2tr9DhUzy0lRdz2lY1v7KHcoLAKmAden94VN2r8t6R7gi8C2Jt1MZtYRFHTXE/jOp/aU5y2pvwROA46RVA9cSykM7pU0HVgPTE6rP0DpdtS1lG5JvTCvuszMbO9yC4WIOG8vi8Y3s24Al+VVi5mZtY474szMLONQMDOzjEPBzMwyHhDPzDo+DwLYbhwKZtbxeRDAdtP5Ys7MzNrMoWBmZhmHgpmZZRwKZmaWcSiYmVnGoWBmZhmHgpmZZfw7BTOztuqEz5BwKJiZtVUnfIaEu4/MzCzjUDAzs4xDwczMMg4FMzPLOBTMzCzjUDAzs4xDwczMMg4FMzPLOBTMzCzjUDAzs4xDwczMMg4FMzPLHFShIGmCpJckrZV0VdH1mJlVmoMmFCR1Bf4XcAZwPHCepOOLrcrMrLIcNKEAfAFYGxGvRMSHwD3ApIJrMjOrKIqIomsAQNLZwISI+Ls0PxX4YkR8e4/1ZgAz0uxQ4PmyFlq8Y4DXiy6izPyZK0OlfeYiP++giOjT3IIO95CdiJgNzAaQVBcRtQWXVFb+zJXBn7nzO1g/78HUfbQRGNBkvjq1mZlZmRxMofAUMETSYEk9gHOBRQXXZGZWUQ6a7qOI2Cnp28DDQFfgZxHxQgubzc6/soOOP3Nl8Gfu/A7Kz3vQXGg2M7PiHUzdR2ZmVjCHgpmZZTpsKFTakBiSBkhaJulFSS9IuqLomspBUldJz0j6TdG1lIOkoyQtkLRG0mpJo4quKW+Svpv+m35e0i8lVRVdU3uT9DNJWyQ936Stl6TFkl5O70cXWWOjDhkKFTokxk7gHyLieGAkcFkFfGaAK4DVRRdRRrcAD0XE54BhdPLPLqk/8B2gNiKGUrrJ5Nxiq8rFHGDCHm1XAUsiYgiwJM0XrkOGAhU4JEZEbIqIp9P0O5T+WPQvtqp8SaoG/gK4o+haykHSkcBY4E6AiPgwIt4qtqqy6Ab0lNQNOBT4c8H1tLuIeAx4Y4/mScDcND0XOKusRe1FRw2F/sCGJvP1dPI/kE1JqgFOBp4stpLc/Rj4J+Cjogspk8FAA3BX6jK7Q9JhRReVp4jYCNwIvApsArZFxCPFVlU2fSNiU5p+DehbZDGNOmooVCxJhwO/Bq6MiLeLricvks4EtkTEiqJrKaNuwAjg1og4GXiPg6RLIS+pH30SpUD8DHCYpP9ebFXlF6XfBhwUvw/oqKFQkUNiSOpOKRDmR8R9RdeTs1OBv5K0jlL34DhJPy+2pNzVA/UR0XgGuIBSSHRmXwX+FBENEbEDuA8YXXBN5bJZUj+A9L6l4HqAjhsKFTckhiRR6mteHRE3FV1P3iLi6oiojogaSv9+l0ZEp/4GGRGvARskHZuaxgMvFlhSObwKjJR0aPpvfDyd/OJ6E4uAaWl6GrCwwFoyB80wF/ujjUNidHSnAlOB5yStTG3/EhEPFFiTtb/Lgfnpy84rwIUF15OriHhS0gLgaUp32D3DQTr8w4GQ9EvgNOAYSfXAtcD1wL2SpgPrgcnFVbibh7kwM7NMR+0+MjOzHDgUzMws41AwM7OMQ8HMzDIOBTMzyzgUzMws41CwiiLpOkn/ow3b/TG91zQd/tiss3EomLVCRBxUQy+kEUXN2p1DwTo9SddI+r+Sfg8cm9r+q6SHJK2QtFzS51J7X0n3S1qVXqNT+7vN7LerpB9JekrSs5Iu3kcN/SQ9JmllepjMmNQ+QdLT6VhLUlsvSf+W9vmEpJNS+3WS7pb0B+BuSX0k/Tod/ylJp7b3PzurPP62YZ2apFMojZ00nNJ/708DKygNpXBJRLws6YvA/wbGAbOARyPir9PDnA7fx+6nUxrq+fOSDgH+IOmRiPhTM+v+LfBwRPwg7fdQSX2A24GxEfEnSb3Sut8DnomIsySNA+al+qH0UKkvRcQHkn4B3BwRv5c0kNKwL8e16R+UWeJQsM5uDHB/RLwPIGkRUEVpJM5/LY3BBsAh6X0ccD5AROwCtu1j318DTpJ0dpo/EhgCNBcKTwE/SyPd/ltErJR0GvBYY4hERONDWL4EfCO1LZXUW9Kn0rJFEfFBmv4qcHyTz/ApSYdHxCfOasxay6FglagL8FZEDG9xzX0TcHlEPNzSihHxmKSxlJ4kN0fSTcCbbTjme02muwAjI2J7G/Zj1ixfU7DO7jHgLEk9JR0B/CXwPvAnSedAaVhyScPS+kuAv0/tXdMjMvfmYeDv07d/JP23vT0pTdIgYHNE3E7p8aIjgCeAsZIGp3Uau4+WA1NS22nA63t5oNIjlEZVbTzGgYacmUPBOrf0XOtfAauAByl140Dpj+50SauAF9j9jO8rgK9Ieo7StYfj97H7Oyg97+DpdJvqT9n72fdpwCpJzwDfBG6JiAZgBnBfquNXad3rgFMkPUtpeOVpn9wdkB54ny5Ivwhcso9azVrFQ2ebmVnGZwpmZpbxhWazdiTpRODuPZr/MyK+WEQ9ZvvL3UdmZpZx95GZmWUcCmZmlnEomJlZxqFgZmaZ/w+H/2jvNY2yTgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...added a column specifying the COMPAS prediction (predict \"will recidivate\" if COMPAS score > 4, otherwise predict \"won't recidivate\")..."
      ],
      "metadata": {
        "id": "5gxUuq-hTy9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 4\n",
        "pp_data['COMPAS_prediction'] = 1 * (pp_data['decile_score'] > threshold)"
      ],
      "metadata": {
        "id": "xT2B943CTjL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...showed that the accuracy is similar for Black and white defendants..."
      ],
      "metadata": {
        "id": "X1p2hKn-hCq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pp_data_black = pp_data[pp_data['race'] == 'African-American']\n",
        "correct_predictions_black = pp_data_black[pp_data_black['two_year_recid'] == pp_data_black['COMPAS_prediction']]\n",
        "accuracy_black = len(correct_predictions_black) / len(pp_data_black)\n",
        "print(f\"For Black defendants: accuracy = {accuracy_black:.4f}\")\n",
        "pp_data_white = pp_data[pp_data['race'] == 'Caucasian']\n",
        "correct_predictions_white = pp_data_white[pp_data_white['two_year_recid'] == pp_data_white['COMPAS_prediction']]\n",
        "accuracy_white = len(correct_predictions_white) / len(pp_data_white)\n",
        "print(f\"For white defendants: accuracy = {accuracy_white:.4f}\")"
      ],
      "metadata": {
        "id": "ss7rfWtohGRg",
        "outputId": "b2af1824-0977-428c-9e72-588e1b0c1c37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Black defendants: accuracy = 0.6491\n",
            "For white defendants: accuracy = 0.6719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...and calculated the FPR and FNR for Black and white defendants:"
      ],
      "metadata": {
        "id": "iF8XCy6cUI3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TN_black, FP_black, FN_black, TP_black = confusion_matrix(pp_data_black['two_year_recid'], pp_data_black['COMPAS_prediction']).ravel()\n",
        "FPR_black = FP_black / (FP_black + TN_black)\n",
        "FNR_black = FN_black / (TP_black + FN_black)\n",
        "print(f\"For Black defendants: FPR = {FPR_black:.4f}, FNR = {FNR_black:.4f}\")\n",
        "TN_white, FP_white, FN_white, TP_white = confusion_matrix(pp_data_white['two_year_recid'], pp_data_white['COMPAS_prediction']).ravel()\n",
        "FPR_white = FP_white / (FP_white + TN_white)\n",
        "FNR_white = FN_white / (TP_white + FN_white)\n",
        "print(f\"For white defendants: FPR = {FPR_white:.4f}, FNR = {FNR_white:.4f}\")"
      ],
      "metadata": {
        "id": "DYM0P27LT-UK",
        "outputId": "32caa226-401a-4852-b261-6e25504b7448",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Black defendants: FPR = 0.4234, FNR = 0.2848\n",
            "For white defendants: FPR = 0.2201, FNR = 0.4964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The FPR and FNR are very different for Black and white defendants, leading ProPublica (and you?) to conclude that COMPAS is racially biased. \n",
        "\n",
        "ProPublica is using a definition of fairness called **Equalized Odds,** which says that the TPR is equal for both groups, and so is the FPR. COMPAS fails the equalized odds test."
      ],
      "metadata": {
        "id": "-wFn92TUZ3sV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the first notebook, you also built the ROC curve for COMPAS:"
      ],
      "metadata": {
        "id": "uTMZgXcuVVS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FPR, TPR, _ = roc_curve(pp_data['two_year_recid'], pp_data['decile_score'])\n",
        "AUC = roc_auc_score(pp_data['two_year_recid'], pp_data['decile_score'])\n",
        "plt.plot(FPR, TPR)\n",
        "plt.plot([(0, 0), (1, 1)], 'r--')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title(f'ROC Curve: COMPAS\\n AUC: {AUC:.4f}');"
      ],
      "metadata": {
        "id": "CwctN5z7UVE0",
        "outputId": "d4447608-63da-4050-f9af-733f1eb10340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "> ðŸ¤“ **Nerd detail:** The `, _` is sort of funny in this line:\n",
        ">\n",
        "> ```\n",
        "FPR, TPR, _ = roc_curve(pp_data['two_year_recid'], pp_data['decile_score'])\n",
        "```\n",
        ">\n",
        "> What's happening here is that the function `roc_curve()` returns three values, but we only care about the first two of them. We can't just write\n",
        ">\n",
        "> ```\n",
        "FPR, TPR = roc_curve(pp_data['two_year_recid'], pp_data['decile_score'])\n",
        "```\n",
        "> because Python won't let us squeeze three values into two variables. But we can use `_` in the third slot, which just means \"throw this value away.\"\n",
        "---"
      ],
      "metadata": {
        "id": "-eWPeIVxj01z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goals for This Notebook\n",
        "\n",
        "In this notebook, we have two main goals:\n",
        "* Examine the fairness argument made by Northpointe (the company that makes COMPAS, now called Equivant) \n",
        "* Discuss the concept of _explainable_ models"
      ],
      "metadata": {
        "id": "7IsngprZVfez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reminder of Key Metrics\n",
        "\n",
        "Recall the **confusion matrix:**\n",
        "\n",
        "<center>\n",
        "\n",
        "|                     | Predicted Positive | Predicted Negative |\n",
        "|---------------------|--------------------|--------------------|\n",
        "| **Actual Positive** | TP                 | FN                 |\n",
        "| **Actual Negative** | FP                 | TN                 |\n",
        "\n",
        "</center>\n",
        "\n",
        "In the confusion matrix,\n",
        "- TP = true positive = actual positives that the model predicted are positive\n",
        "- FN = false negative = actual positives that the model predicted are negative\n",
        "- FP = false positive = actual negatives that the model predicted are positive\n",
        "- TN = true negative = actual negatives that the model predicted are negative\n",
        "\n",
        "The **accuracy** of a model is the total proportion (percentage) of individuals that are correctly classified:\n",
        "\n",
        "<p align=\"center\">accuracy = (TP + TN) / (TP + FN + FP + TN)</p>\n",
        "\n",
        "We also introduced the following metrics:\n",
        "- TPR = true positive rate = TP / (TP + FN) = fraction of actual positives that the model predicted are positive\n",
        "- FNR = false negative rate = FN / (TP + FN) = fraction of actual positive that the model predicted are negative\n",
        "- FPR = false positive rate = FP / (FP + TN) = fraction of actual negatives that the model predicted are positive\n",
        "- TNR = true positive rate = TN / (FP + TN) = fraction of actual negatives that the model predicted are not positive\n",
        "\n",
        "You can think of these as being \"row-based\" measures: They look at all individuals in a row (i.e., all actual positives or all actual negatives) and ask, \"Of all the individuals that are actually positive [or negative], what proportion did the model correctly predict are positive [or negative]?\"\n"
      ],
      "metadata": {
        "id": "nnguuC8adQhU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Northpointe's Argument\n",
        "\n",
        "After ProPublica's [article](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) was published, Northpointe published a [rebuttal](https://go.volarisgroup.com/rs/430-MBX-989/images/ProPublica_Commentary_Final_070616.pdf), taking issues with many of ProPublica's arguments and presenting its own evidence that COMPAS is, in fact, fair.\n",
        "\n",
        "Northpointe argued for COMPAS's fairness using two main definitions of fairness:\n",
        "* Accuracy equity\n",
        "* Predictive parity\n",
        "\n",
        "We will explore each of these metrics next.\n"
      ],
      "metadata": {
        "id": "5mxkKXP-WH4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy Equity\n",
        "\n",
        "Northpointe argued that the overall accuracy is similar for Black and white defendants. You already showed this is true in the previous notebook, and we recapped it in the earlier section of this one. If you need yet another recap:"
      ],
      "metadata": {
        "id": "5faHkRO_cT39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"For Black defendants: accuracy = {accuracy_black:.4f}\")\n",
        "print(f\"For white defendants: accuracy = {accuracy_white:.4f}\")"
      ],
      "metadata": {
        "id": "HGk66hZfVb-_",
        "outputId": "e9577165-643f-4d76-f128-7a612b961c3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Black defendants: accuracy = 0.6491\n",
            "For white defendants: accuracy = 0.6719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, Northpointe is arguing that COMPAS exhibits **Accuracy Equity,** which says that the accuracy is the same for the two groups.\n",
        "\n",
        "Northpointe further argued that the **AUC** is similar for Black and white defendants. Recall that the **ROC** curve plots the TPR vs. the FPR for various thresholds, and the AUC is the area under that curve. In the first notebook (and earlier in this one), we plotted the ROC and calculated the AUC *for all defendants.*"
      ],
      "metadata": {
        "id": "17eYLimphzR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**\n",
        "\n",
        "Plot the ROC curve for only Black defendants, and the ROC curve for only white defendants, on the same plot. Also calculate the AUC for only Black defendants and the AUC for only white defendants.\n",
        "\n",
        "You write the code to calculate \n",
        "* `FPR_black`, `TPR_black`, `AUC_black`, and\n",
        "* `FPR_white`, `TPR_white`, `AUC_white`, \n",
        "\n",
        "and I'll write the code to build the plot.\n",
        "\n",
        "*Hint*: Use the code above that calculates `FPR`, `TPR`, and `AUC`, but base your calculates on `pp_data_black` and `pp_data_white` instead of on `pp_data`."
      ],
      "metadata": {
        "id": "uphHcFoUiLC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here:\n",
        "FPR_black, TPR_black, _ = [...]\n",
        "AUC_black = [...]\n",
        "FPR_white, TPR_white, _ = [...]\n",
        "AUC_white = [...]\n",
        "\n",
        "# My code here:\n",
        "plt.plot(FPR_black, TPR_black)\n",
        "plt.plot(FPR_white, TPR_white)\n",
        "plt.plot([(0, 0), (1, 1)], 'r--')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.legend(['Black', 'white'])\n",
        "plt.title(f'ROC Curve: COMPAS\\n AUC for Black defendants: {AUC_black:.4f}\\n AUC for white defendants: {AUC_white:.4f}');"
      ],
      "metadata": {
        "id": "2r8FitPYjmpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ROC curves look quite similar, and the AUC values are quite similar, between Black and white defendants. Northepoint used this as further evidence that COMPAS does not show racial bias."
      ],
      "metadata": {
        "id": "ASvB9Ychkxt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictive Parity"
      ],
      "metadata": {
        "id": "cbsU_ieJlzt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here come two more accuracy metrics ðŸ˜¬:\n",
        "\n",
        "- PPV = positive predictive value = TP / (TP + FP) = fraction of predicted positives that are actually positive\n",
        "- NPV = negative predictive value = TN / (FN + TN) = fraction of predicted negatives that are actually negative\n",
        "\n",
        "Remember that TPR, FPR, etc. are \"row-based\" metrics: They look at all individuals in a row (i.e., all actual positives or all actual negatives) and ask, \"Of all the individuals that are actually positive [or negative], what proportion did the model correctly predict are positive [or negative]?\"\n",
        "\n",
        "In contrast, PPV and NPV are \"column-based\" metrics: They look at all individuals in a column (i.e., all predicted positives or all predicted negatives) and ask, \"Of all the individuals that the model predicted as positive [or negative], what proportion are actually positive [or negative]?\"\n",
        "\n",
        "Let's examine the PPV and NPV for Black and white defendants.\n"
      ],
      "metadata": {
        "id": "VnfOsc7vl--8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**\n",
        "\n",
        "Calculate the PPV and NPV for Black and white defendants. Store them in variables called `PPV_black`, `NPV_black`, `PPV_white`, and `NPV_white`.\n",
        "\n",
        "*Hint*: You have already calculated TN, FP, etc. for Black and white defendants. Use those variables."
      ],
      "metadata": {
        "id": "kIZqGfC1nUpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[...]"
      ],
      "metadata": {
        "id": "dx22dPTkroIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Northpointe points out that the PPV is similar for Black and white defendants, and so is the NPVâ€”in fact, the PPV is even somewhat better for Black defendants. They use this to argue that COMPAS is fair. \n",
        "\n",
        "This is based on yet another definition of fairness, namely, **Predictive Parity,** which says that PPV is equal for the two groups, and so is NPV.\n",
        "\n",
        "Actually, Northpointe doesn't use PPV and NPV, they use 1 â€“ PPV and 1 â€“ NPV. (Mathematically, the two arguments are the same, because if PPV is equal for two groups, then so is 1 â€“ PPV, and similarly for NPV.) In their rebuttal, they give the following table, which they claim is \"a corrected version of the table that [ProPublica] presented under the\n",
        "heading 'Prediction Fails Differently for Black Defendants.'\":\n",
        "\n",
        "<center><img src=\"https://github.com/LarrySnyder/ASJ/raw/main/compas/images/northpointe_table.png\" width=\"500\"/></center>\n",
        "\n",
        "Northpointe interprets \"labeled higher risk, but didn't re-offend\" as the percentage of people who were predicted \"positive\" (predicted to recidivate) but were actually negative, i.e., 1 â€“Â PPV.\n",
        "\n",
        "And they interpret \"labeled lower risk, yet did re-offend\" as the percentage of people who were predicted \"negative\" (predicted not to recidivate) but were actually positive, i.e., 1 â€“Â NPV.\n",
        "\n",
        "Let's recreate this table based on the variables you defined in Question 2."
      ],
      "metadata": {
        "id": "fi48T4ITpjtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "table = [[\"Labeled Higher Risk, But Didn't Re-Offend\", \n",
        "            f\"{100*(1 - PPV_white):.0f}%\", \n",
        "            f\"{100*(1 - PPV_black):.0f}%\"],\n",
        "         [\"Labeled Lower Risk, Yet Did Re-Offend\", \n",
        "            f\"{100*(1 - NPV_white):.0f}%\", \n",
        "            f\"{100*(1 - NPV_black):.0f}%\"]]\n",
        "headers = [\"White\", \"African American\"]\n",
        "print(tabulate(table, headers=headers))"
      ],
      "metadata": {
        "id": "9grgk3S8owp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Our numbers are a little different, again due to small differences in the way we processed and analyzed the data.)"
      ],
      "metadata": {
        "id": "-7Gd0rkMtvKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How Can They Both Be Right?\n",
        "\n",
        "**ProPublica says:** FPR and FNR are different for different races; therefore COMPAS is unfair.\n",
        "\n",
        "**Northpoint says:** PPV and NPV are the same for different races; therefore COMPAS is fair.\n",
        "\n",
        "*How can they both be right?*\n",
        "\n",
        "In the best spirit of interdisciplinary learning, we'll give two answers, one based on language and one based on math."
      ],
      "metadata": {
        "id": "YLcNfTE8vjbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 1: Imprecise Language\n",
        "\n",
        "Recall ProPublica's famous table:\n",
        "\n",
        "<center><img src=\"https://github.com/LarrySnyder/ASJ/raw/main/compas/images/propublica_table.png\" width=\"500\"/></center>\n",
        "\n",
        "ProPublica's language here is imprecise. It's clear that \"labeled higher risk, but didn't re-offend\" is referring to false positives (FP) and that \"labeled lower risk, yet did re-offend\" is referring to false negatives (FN). \n",
        "\n",
        "But they are not reporting the *numbers* of FP and FN, they are reporting *percentages*, which means they need to divide by something. And the captions (\"Labeled Higher Risk...\") are not specific enough to tell us what to divide by.\n",
        "\n",
        "ProPublica used the **FPR and FNR**. That is, they divided by the numbers of **actual positives and negatives.** (Remember: FPR = FP / (FP + TN) and FNR = FN / (TP + FN).)\n",
        "\n",
        "Northpointe used **1 â€“ PPV and 1 â€“Â NPV**. That is, they divided by the numbers of of **predicted positives and negatives.** (Remember: 1 â€“Â PPV = 1 â€“Â TP / (TP + FP) = FP / (TP + FP) and 1 â€“Â NPV = 1 â€“Â TN / (FN + TN) = FN / (FN + TN).)\n",
        "\n",
        "That's how Northpointe was able to produce a table with *exactly the same captions as ProPublica's* but with completely different results:\n",
        "\n",
        "<center><img src=\"https://github.com/LarrySnyder/ASJ/raw/main/compas/images/northpointe_table.png\" width=\"500\"/></center>"
      ],
      "metadata": {
        "id": "xTZ983ihwOsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 2: Mathematical Impossibility\n",
        "\n",
        "Remember the following two definitions of fairness:\n",
        "\n",
        "* **Equalized Odds:** TPR is equal for both groups, and so is FPR.\n",
        "* **Predictive Parity:** PPV is equal for both groups, and so is NPV. \n",
        "\n",
        "---\n",
        "> ðŸ‘“ **Note:** When we say \"equal,\" we mean equal in a sort of statistical, expected-value sense. In practice, with real data, these metrics will not typically be equal. But if they are equal*ish*, we can say the model is fair*ish* with respect to equalized odds and/or predictive parity.\n",
        "---\n",
        "\n",
        "Using these terms, we can rephrase the two arguments as:\n",
        "\n",
        "**ProPublica says:** equalized odds **does not hold** for COMPAS; therefore COMPAS is unfair.\n",
        "\n",
        "**Northpoint says:** predictive parity **does hold** for COMPAS; therefore COMPAS is fair."
      ],
      "metadata": {
        "id": "OoRyJaSXzKkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It turns out that this is inevitable, from a mathematical point of view, due to the following **impossibility theorem:**\n",
        "\n",
        "> **Theorem.** Equalized odds and predictive parity cannot both hold for the same predictor, unless the predictor is *perfect* or the two groups have the *same base rate.*\n",
        "\n",
        "(This theorem was proved after, and largely in response to, the ProPublicaâ€“Northpointe debate. See [Chouldechova (2016)](https://arxiv.org/abs/1610.07524), [Kleinberg, et al. (2016)](https://arxiv.org/abs/1609.05807), and [Miconi (2017)](https://arxiv.org/abs/1707.01195).)\n",
        "\n",
        "By \"perfect,\" we mean the predictor gets it right 100% of the time. Few predictors are perfect. COMPAS certainly is not.\n",
        "\n",
        "By \"same base rate,\" we mean that the two groups have the same prevalence of the thing being predicted. In the case of COMPAS, this would mean that Black and white defendants have the same two-year-recidivism rate. \n",
        "\n",
        "The data tells us that this is not the case:"
      ],
      "metadata": {
        "id": "NsmSBpCj09HP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "did_recidivate_black = pp_data_black[pp_data_black['two_year_recid'] == 1]\n",
        "base_rate_black = len(did_recidivate_black) / len(pp_data_black)\n",
        "did_recidivate_white = pp_data_white[pp_data_white['two_year_recid'] == 1]\n",
        "base_rate_white = len(did_recidivate_white) / len(pp_data_white)\n",
        "print(f\"Proportion of Black defendants who recidivated = {base_rate_black:.4f}\")\n",
        "print(f\"Proportion of White defendants who recidivated = {base_rate_white:.4f}\")"
      ],
      "metadata": {
        "id": "JwjDtGOerufA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two base rates are not the same. Of course, this is not a surprise, for reasons we have already discussed in class: As [Michelle Alexander](https://newjimcrow.com/) has argued, the U.S. criminal justice system essentially criminalizes Blackness; and as [Cathy O'Neil](https://www.penguinrandomhouse.com/books/241363/weapons-of-math-destruction-by-cathy-oneil/) and others have argued, PredPol and other predictive policing algorithms ensure that Black communities are over-policed.\n",
        "\n",
        "So: no model is a perfect predictor, and different races have different base rates of recividism â€” hence, it is *mathematically impossible* for COMPAS or any other model to be fair in terms of both equalized odds and predictive parity."
      ],
      "metadata": {
        "id": "f9h6UfH53I7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3**\n",
        "\n",
        "Does one of these fairness measures resonate with you more strongly? Does one seem \"fairer\" than the other? If you had to choose one for your model, which would you choose, and why?"
      ],
      "metadata": {
        "id": "Awv8_Qljb9Ms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** *YOUR ANSWER HERE*"
      ],
      "metadata": {
        "id": "tu3znH7zcOe1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## On Transparency (or Lack Thereof)\n",
        "\n",
        "There has been a lot of discussion in recent years about the fact that many machine learning (ML) and other models are *black boxes,* and therefore that they make it difficult for humansâ€”even the humans who designed the algorithmsâ€”to understand what the model is doing, and why. Therefore, there has been a lot of research in the ML community to develop *explainable ML*, or to develop models that are *interpretable* in the first place. In this section, we'll explore these terms (black box, explainable, interpretable) in the context of COMPAS.\n",
        "\n",
        "Of course, being able to understand what a model is doing is important for fairness. Recall O'Neil's argument that *opacity* is one of the three hallmarks of a weapon of math destruction (WMD)."
      ],
      "metadata": {
        "id": "lyfwA-DQL-RG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Black Boxes, Explainability, and Interpretability\n",
        "\n",
        "In her [paper](https://www.nature.com/articles/s42256-019-0048-x) \"Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead,\" Cynthia Rudin argues that there are two types of **black boxes:**\n",
        "\n",
        "> A black box model could be either (i) a function that is too complicated for any human to comprehend, or (ii) a function that is proprietary\n",
        "\n",
        "For example, deep learning models tend to be the first type of black boxesâ€”even if we understand the structure of the algorithm, the calculations are so complicated that trying to trace the intuition behind the decisions being made at each iteration of the algorithm quickly becomes hopeless.\n",
        "\n",
        "On the other hand, COMPAS is the second kind of black boxâ€”we don't know what it's doing, simply because Northpointe won't tell us. They regard it as a trade secret. (It's possible that COMPAS is also the first type of black box. However, in [another paper](https://hdsr.mitpress.mit.edu/pub/7z10o269/release/7), Rudin provides evidence that it is probably notâ€”it is probably a relatively simple model.)\n",
        "\n",
        "Rudin decries the recent trend toward **explainable ML:**\n",
        "\n",
        "> there has been a recent explosion of\n",
        "work on â€œExplainable ML,â€ where a second (posthoc) model is created to explain the first black box model. This is problematic. Explanations are often not reliable, and can be misleading\n",
        "\n",
        "In fact, she argues that ProPublica's attempts to recreate COMPAS's black box are incorrect, and that ProPublica draws incorrect conclusions as a result. But that's another story, which we won't get into here.\n",
        "\n",
        "Rudin argues that instead of trying to explain ML models, we should instead be using\n",
        "\n",
        "> models that are inherently interpretable, they provide their own explanations, which are faithful to what the model actually computes.\n",
        "\n",
        "In other words, an **interpretable** model is transparent from the get-go, whereas explainable ML tries to reverse-engineer intuition from a black box. \n",
        "\n",
        "In the rest of this notebook, we'll build an interpretable model to predict recidivism. We'll evaluate its accuracy and compare it to the black-box COMPAS model.\n"
      ],
      "metadata": {
        "id": "cxhTpRaVOvTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "> âš ï¸ **Important:** In the first COMPAS notebook, you reproduced ProPublica's analysis of the COMPAS results. In the rest of this notebook, you'll instead be trying to replicate what COMPAS doesâ€”using characteristics of a defendant to predict whether they will recidivateâ€”but using an interpretable model rather than a black box. In other words, you'll be building a competitor to COMPAS.\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Jfo13c9cTCbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recap: The \"Titanic\" Model\n",
        "\n",
        "In the next section, you will build a **decision tree** model to predict recidivism risk. Recall from the \"Titanic\" notebook that a decision tree is a type model that uses a series of \"branches\" (yes/no answers to questions about the data) to lead to a prediction. Because the decision tree is \"trained\" using data (that is, because the choices of which features to branch on is driven by data), decision trees are considered to be a type of ML model.\n",
        "\n",
        "Here's a quick recap of how we built the decision tree in the \"Titanic\" notebook.\n"
      ],
      "metadata": {
        "id": "DOwF1GDOTuGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data.\n",
        "train_url = \"https://raw.githubusercontent.com/datacamp/datacamp_facebook_live_titanic/master/data/train.csv\"\n",
        "train = pd.read_csv(train_url)"
      ],
      "metadata": {
        "id": "0fCaxFLRViDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the data.\n",
        "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())"
      ],
      "metadata": {
        "id": "SbcRqT9gVh6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert \"Sex\" to a numeric value instead of text (because that's what the \n",
        "# algorithm requires).\n",
        "encoded_sex = preprocessing.LabelEncoder()\n",
        "train[\"Sex_numeric\"] = encoded_sex.fit_transform(train[\"Sex\"])"
      ],
      "metadata": {
        "id": "tBxIvB1WWH1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create arrays for the \"target\" (the outcome variable, i.e., value we are \n",
        "# trying to predict, in this case the \"Survived\" column) and the \"features\" \n",
        "# (the predictive variables, i.e., the values we are using to make the prediction,\n",
        "# in this case the fare class, sex, age, and fare).\n",
        "target = train[\"Survived\"].values\n",
        "feature_names = [\"Pclass\", \"Sex_numeric\", \"Age\", \"Fare\"]\n",
        "features = train[feature_names].values"
      ],
      "metadata": {
        "id": "eRbRXRSEVhzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the decision tree and fit it.\n",
        "my_tree = tree.DecisionTreeClassifier(max_depth=2)\n",
        "my_tree = my_tree.fit(features, target)"
      ],
      "metadata": {
        "id": "fmGYQDHC257z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note*: We didn't use the argument `max_depth=2` in the \"Titanic\" notebook, but we'll use it here. It keeps the tree smaller and more manageable."
      ],
      "metadata": {
        "id": "DDzyZSbNW3Zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw a plot of the decision tree.\n",
        "plt.figure(figsize=(10, 10))\n",
        "tree.plot_tree(my_tree, feature_names=feature_names, class_names=[\"NO\", \"YES\"], max_depth=2, filled=True);"
      ],
      "metadata": {
        "id": "879lKdQoXHJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way of visualizing the decision tree, instead of drawing it, is to have the decision tree list its decision rules in text form:"
      ],
      "metadata": {
        "id": "8iwjOQzdXV7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tree.export_text(my_tree, feature_names=feature_names))"
      ],
      "metadata": {
        "id": "cKGa3qhmXcwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both of these outputs tell us the same thing; they translate to the following rules, in human language:\n",
        "\n",
        "* If `Sex_numeric` = 0 (this means that `Sex` = \"female\"):\n",
        "  * If `Pclass` â‰¤ 2, predict **YES** (the passenger survived)\n",
        "  * If `Pclass` = 3, predict **NO** (the passenger did not survived)\n",
        "* If `Sex_numeric` = 1 (`Sex` = \"male\"):\n",
        "  * If `Age` â‰¤ 6.5, predict **YES**\n",
        "  * If `Age` > 6.5, predict **NO**"
      ],
      "metadata": {
        "id": "l70fB7ZKXvRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A decision tree is inherently **interpretable,** because we know exactly how it is making the predictions it is making. If the model looks at a 10-year-old boy and predicts that he died, we know the logic that led to the model's decision. If it turns out the boy survived, we can understand where the model went wrong. If it turns out that the boy was actually 5, not 10, we can understand how the result would change."
      ],
      "metadata": {
        "id": "PGtxT_gjVhJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Decision Tree Model for Recidivism Risk\n",
        "\n",
        "Now it's your turn. You'll build a decision tree for recidivism risk. One option would be to use the 137 features on Northpointe's questionairre as your predictive variablesâ€”that's what the COMPAS tool does. But (a) we don't have those data, and (b) it turns out we can build a pretty good predictor with much simpler, less intrusive features. So that's what we'll do.\n",
        "\n",
        "Earlier in this notebook, you already loaded ProPublica's dataset and did some filtering. At this point, the notebook should still remember the resulting DataFrame, called `pp_data`. (If not, just re-run the cells up to this point.)\n",
        "\n",
        "Let's double-check:"
      ],
      "metadata": {
        "id": "QoSrf60gZWIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pp_data"
      ],
      "metadata": {
        "id": "9i3n3zQDZbF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the Model\n",
        "\n",
        "**Question 4**\n",
        "\n",
        "The decision tree algorithm requires the features to be stored as numbers, not text. So, just like we converted \"Sex\" to a numeric value in the \"Titanic\" data, we'll convert both \"sex\" and \"race\" to numeric values in the ProPublica data. I'll do \"sex\", you do \"race\"."
      ],
      "metadata": {
        "id": "RxGBtk7BaSiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert values in \"sex\" column to numeric values.\n",
        "encoded_sex = preprocessing.LabelEncoder()\n",
        "pp_data['sex_numeric'] = encoded_sex.fit_transform(pp_data['sex'])\n",
        "\n",
        "# Convert values in \"race\" column to numeric values.\n",
        "encoded_race = [...]\n",
        "pp_data['race_numeric'] = [...]"
      ],
      "metadata": {
        "id": "dgx8Kf4nZOBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we have to split our data into **testing data** and **training data.** We'll use a 70/30 split. In the \"Titanic\" notebook, the dataset was already split (because it was part of a competition, and the outcome variables were removed from the training data).\n",
        "\n",
        "There are several ways to do this; for a discussion of a few of them, see https://stackoverflow.com/q/24147278/3453768. It's OK if you don't understand the next code block."
      ],
      "metadata": {
        "id": "NkQur2n0avhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pp_data.sample(frac=0.7, random_state=200)\n",
        "test = pp_data.drop(train.index)"
      ],
      "metadata": {
        "id": "GlzUePP3bQ1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we have to create arrays for the `target` and the `features`. \n",
        "\n",
        "**Question 5**\n",
        "\n",
        "Create a variable called `target` and set it equal to the values in the `two_year_recid` column in the `train` DataFrame."
      ],
      "metadata": {
        "id": "VQXPPY8nbxoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[...]"
      ],
      "metadata": {
        "id": "h1isSizCc6iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6**\n",
        "\n",
        "We'll use `age`, `race_numeric`, `sex_numeric`, `priors_count`, and `days_b_screening_arrest` as our features. \n",
        "\n",
        "Create a variable called `feature_names` and set it equal to a list of these column names. (Use the \"Titanic\" recap code as a template. Don't forget to enclose the column names in quotes.)"
      ],
      "metadata": {
        "id": "OgYYj8tuc7SI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[...]"
      ],
      "metadata": {
        "id": "vwQBIqHMdU1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7**\n",
        "\n",
        "Create a variable called `features` and set it equal to the values in the columns of the `train` DataFrame corresponding to the features listed in `feature_names`. (Again, use the \"Titanic\" recap code as a template.)"
      ],
      "metadata": {
        "id": "xCaXU0v1dvi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[...]"
      ],
      "metadata": {
        "id": "VPJYhWQod-Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8**\n",
        "\n",
        "Create a new decision tree, called `my_tree`, and fit it. Use a `max_depth` of 2. (Keep using the \"Titanic\" recap...)"
      ],
      "metadata": {
        "id": "Il7pJni8eHw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[...]"
      ],
      "metadata": {
        "id": "_64M_qzyeAAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9**\n",
        "\n",
        "Draw a plot of the decision tree. You can use the same `class_names` that we used in \"Titanic\". (Here, \"NO\" will mean we predict the defendant will not recidivate and \"YES\" will mean we predict they will.)"
      ],
      "metadata": {
        "id": "lLDL0R40enm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[...]"
      ],
      "metadata": {
        "id": "tRQkFq9Dezfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10**\n",
        "\n",
        "Have the decision tree list its decision rules in text form."
      ],
      "metadata": {
        "id": "vJ2MbH96e6B0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[...]"
      ],
      "metadata": {
        "id": "3naYf6ZPe6B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 11**\n",
        "\n",
        "Write the decision rules in human language. (If you want to use the same formatting as we did in \"Titanic\", double-click the text cell, copy the text, paste it below, and edit as needed. But it's fine if you don't format it in any particular way.)\n",
        "\n"
      ],
      "metadata": {
        "id": "w9dHLNoxfWhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** *YOUR ANSWER HERE*"
      ],
      "metadata": {
        "id": "KqPtC9Gzfz6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the Model\n",
        "\n",
        "We'd like to know how accurate this model is, especially compared to COMPAS. If its accuracy is much worse, it suggests that there is a tradeoff (at least in this case) between accuracy and transparencyâ€”if we want one, we can't have the other. On the other hand, if our model is still pretty accurate, it suggests we can have both.\n",
        "\n",
        "You already built `target` and `features` arrays for the training data. But now we want to test our model on the testing data, so we'll need arrays for the testing data too."
      ],
      "metadata": {
        "id": "JJLssAFNgWJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 12**\n",
        "\n",
        "Build two new variables, called `target_test` and `features_test`. Set `target_test` equal to the values in the `two_year_recid` column in the `test` DataFrame. Set `features_test` equal to the values in the columns of the `test` DataFrame corresponding to the features listed in `feature_names`. (You don't need to define `feature_names` again; it's still the same as last time.)"
      ],
      "metadata": {
        "id": "F4bZbVA_g8TO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[...]"
      ],
      "metadata": {
        "id": "bM-HBqI7fUj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can calculate the accuracy of your model on the testing data:"
      ],
      "metadata": {
        "id": "lIyTRQ-ph_Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy on testing data.\n",
        "my_tree.score(features_test, target_test)"
      ],
      "metadata": {
        "id": "m32K6fcfh63K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 13**\n",
        "\n",
        "How good is the accuracy of your decision tree model, compared to the accuracy of COMPAS?"
      ],
      "metadata": {
        "id": "7jnZt2gdiLLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** *YOUR ANSWER HERE*"
      ],
      "metadata": {
        "id": "64fHyZADiRXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wrapping Up\n",
        "\n",
        "Rudin argues that there is great value to having an interpretable model. She uses a different method for building a decision tree, but the overall approach is similar. The decision rules she winds up with are:\n",
        "\n",
        "<center><img src=\"https://github.com/LarrySnyder/ASJ/raw/main/compas/images/rudin_rules.png\" width=\"600\"/></center>\n",
        "\n",
        "Her model's accuracy is slightly better than the accuracy of your decision tree.\n",
        "\n",
        "We could dig deeper to evaluate racial bias in the decision tree model, as ProPublica and Northpointe did for the COMPAS model. We won't do that in this notebook, but *feel free to do it on your own!* (It's not hard; you'd just be following the same templates that we've used already.)\n",
        "\n",
        "If you did that analysis, though, you'd find that:\n",
        "* The accuracy is similar for Black and white defendants (66% vs. 64%).\n",
        "* Under ProPublica's fairness measure (equalized odds, based on FPR and FNR), the decision tree model fares as badly as COMPAS, if not worse.\n",
        "* Under Northpointe's fairness measure (predictive parity, based on PPV and NPV), the decision tree model is a mixed bag: pretty equal in terms of NPV but pretty unequal in terms of PPV, with white defendants having worse accuracy than Black defendants in the latter sense.\n",
        "\n"
      ],
      "metadata": {
        "id": "1n1pxiKHt6y-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 14**\n",
        "\n",
        "What would be some of the advantages and disadvantages of using your decision tree model instead of COMPAS? "
      ],
      "metadata": {
        "id": "nVPzMVqvyGuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** *YOUR ANSWER HERE*"
      ],
      "metadata": {
        "id": "DTDNYfifyX8G"
      }
    }
  ]
}